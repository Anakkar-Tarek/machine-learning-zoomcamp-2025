{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f899b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.5' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Users/Win11 Pro/AppData/Local/Programs/Python/Python313/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical & numerical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "num_cols = df.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Fill missing values:\n",
    "# - Categorical → 'NA'\n",
    "# - Numerical → 0.0\n",
    "df[cat_cols] = df[cat_cols].fillna('NA')\n",
    "df[num_cols] = df[num_cols].fillna(0.0)\n",
    "\n",
    "# Check if any missing values remain\n",
    "df.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a50bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['industry'].mode()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(numeric_only=True)\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7e5ba",
   "metadata": {},
   "source": [
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "for a, b in pairs:\n",
    "    print(f\"{a} vs {b}: {corr.loc[a, b]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac708b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target\n",
    "target = 'converted'\n",
    "\n",
    "# Split: 60% train, 20% val, 20% test\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)  # 0.25 of 0.8 = 0.2 overall\n",
    "\n",
    "# Reset indices\n",
    "for subset in (df_train, df_val, df_test):\n",
    "    subset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "len(df_train), len(df_val), len(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d65d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[target])\n",
    "y_train = df_train[target]\n",
    "\n",
    "# Select categorical features\n",
    "cat_cols = X_train.select_dtypes(['object']).columns\n",
    "\n",
    "mi_scores = {}\n",
    "for col in cat_cols:\n",
    "    mi = mutual_info_classif(X_train[[col]], y_train, discrete_features=True)\n",
    "    mi_scores[col] = round(mi[0], 2)\n",
    "\n",
    "mi_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Separate features and target\n",
    "X_train = df_train.drop(columns=[target])\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_val = df_val.drop(columns=[target])\n",
    "y_val = df_val[target]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = X_train.select_dtypes(['object']).columns\n",
    "num_cols = X_train.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# One-hot encode categorical vars\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Logistic Regression model\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_pred)\n",
    "round(val_acc, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline accuracy\n",
    "baseline_acc = accuracy_score(y_val, model.predict(X_val))\n",
    "print(\"Baseline:\", baseline_acc)\n",
    "\n",
    "# Calculate accuracy drop when removing each feature\n",
    "diffs = {}\n",
    "for col in X_train.columns:\n",
    "    X_train_sub = X_train.drop(columns=[col])\n",
    "    X_val_sub = X_val.drop(columns=[col])\n",
    "\n",
    "    model_sub = make_pipeline(\n",
    "        ColumnTransformer([\n",
    "            ('num', 'passthrough', X_train_sub.select_dtypes(exclude=['object']).columns),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), X_train_sub.select_dtypes(['object']).columns)\n",
    "        ]),\n",
    "        LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    )\n",
    "\n",
    "    model_sub.fit(X_train_sub, y_train)\n",
    "    acc = accuracy_score(y_val, model_sub.predict(X_val_sub))\n",
    "    diffs[col] = baseline_acc - acc\n",
    "\n",
    "diffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "results = {}\n",
    "\n",
    "for c in C_values:\n",
    "    model_c = make_pipeline(\n",
    "        preprocessor,\n",
    "        LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    )\n",
    "    model_c.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_val, model_c.predict(X_val))\n",
    "    results[c] = round(acc, 3)\n",
    "\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
